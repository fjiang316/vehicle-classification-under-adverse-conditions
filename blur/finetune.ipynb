{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "619d5936-8530-49a2-a217-fc145f93ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ bicycle: 145 train, 31 val, 32 test\n",
      "✓ boat: 188 train, 40 val, 41 test\n",
      "✓ bus: 198 train, 42 val, 44 test\n",
      "✓ car: 210 train, 45 val, 45 test\n",
      "✓ helicopter: 210 train, 45 val, 45 test\n",
      "✓ motorcycle: 72 train, 15 val, 17 test\n",
      "✓ truck: 210 train, 45 val, 45 test\n",
      "\n",
      "Done! Created:\n",
      " → ./vehicle_dataset2/train\n",
      " → ./vehicle_dataset2/val\n",
      " → ./vehicle_dataset2/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset_three(\n",
    "    source_dir,\n",
    "    output_dir,\n",
    "    classes,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    seed=42\n",
    "):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \\\n",
    "        \"Ratios must sum to 1.0\"\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Output dirs\n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir = os.path.join(output_dir, \"val\")\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for cls in classes:\n",
    "        src_class_dir = os.path.join(source_dir, cls)\n",
    "\n",
    "        if not os.path.exists(src_class_dir):\n",
    "            print(f\"⚠️ Class not found: {src_class_dir}\")\n",
    "            continue\n",
    "\n",
    "        files = [\n",
    "            f for f in os.listdir(src_class_dir)\n",
    "            if os.path.isfile(os.path.join(src_class_dir, f))\n",
    "        ]\n",
    "\n",
    "        random.shuffle(files)\n",
    "\n",
    "        n = len(files)\n",
    "        n_train = int(n * train_ratio)\n",
    "        n_val = int(n * val_ratio)\n",
    "\n",
    "        train_files = files[:n_train]\n",
    "        val_files = files[n_train:n_train+n_val]\n",
    "        test_files = files[n_train+n_val:]\n",
    "\n",
    "        # Create subfolders\n",
    "        dst_train = os.path.join(train_dir, cls)\n",
    "        dst_val   = os.path.join(val_dir, cls)\n",
    "        dst_test  = os.path.join(test_dir, cls)\n",
    "\n",
    "        os.makedirs(dst_train, exist_ok=True)\n",
    "        os.makedirs(dst_val, exist_ok=True)\n",
    "        os.makedirs(dst_test, exist_ok=True)\n",
    "\n",
    "        # Copy files\n",
    "        for f in train_files:\n",
    "            shutil.copy(os.path.join(src_class_dir, f), os.path.join(dst_train, f))\n",
    "\n",
    "        for f in val_files:\n",
    "            shutil.copy(os.path.join(src_class_dir, f), os.path.join(dst_val, f))\n",
    "\n",
    "        for f in test_files:\n",
    "            shutil.copy(os.path.join(src_class_dir, f), os.path.join(dst_test, f))\n",
    "\n",
    "        print(f\"✓ {cls}: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test\")\n",
    "\n",
    "    print(\"\\nDone! Created:\")\n",
    "    print(f\" → {train_dir}\")\n",
    "    print(f\" → {val_dir}\")\n",
    "    print(f\" → {test_dir}\")\n",
    "\n",
    "YOUR_CLASSES = ['bicycle', 'boat', 'bus', 'car', 'helicopter', 'motorcycle', 'truck']\n",
    "\n",
    "split_dataset_three(\n",
    "    source_dir=\"./blurred_cv2\",\n",
    "    output_dir=\"./vehicle_dataset2\",\n",
    "    classes=YOUR_CLASSES,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d4ae52-ea63-48cd-9b67-c2dc0f90100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 12:38:18.399651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-11 12:38:18.399758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-11 12:38:18.402536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-11 12:38:18.427335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-11 12:38:24.915588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 115 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Path to your pretrained CNN\n",
    "model_path = \"mobilenet2.h5\"\n",
    "model = load_model(model_path)\n",
    "YOUR_CLASSES = ['bicycle', 'boat', 'bus', 'car', 'helicopter', 'motorcycle', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d5509d-27b0-4a51-8ef1-6c88a06cbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "outputs = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b9a242-18e1-4bbd-8994-423a4df096ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1233 images belonging to 7 classes.\n",
      "Found 263 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'vehicle_dataset2/train',\n",
    "    target_size=(160, 160),  # match your model input\n",
    "    batch_size=4,\n",
    "    classes=YOUR_CLASSES,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'vehicle_dataset2/val',\n",
    "    target_size=(160, 160),\n",
    "    batch_size=4,\n",
    "    classes=YOUR_CLASSES,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997e503a-60c4-47aa-9439-aef005f47d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5974a464-83d0-4cc7-86a6-6b0e0cec10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 12:38:57.034838: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2025-12-11 12:38:57.833927: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 59.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:57.844570: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 59.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:57.902558: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.40MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:57.913119: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.40MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.014669: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.47MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.025379: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.47MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.051968: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.063342: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.128791: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 142.77MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.140595: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 142.77MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-12-11 12:38:58.597265: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc0dc834850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-11 12:38:58.597355: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2025-12-11 12:38:58.615012: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765456738.915579  268130 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 91s 264ms/step - loss: 1.0639 - accuracy: 0.6188 - val_loss: 0.5445 - val_accuracy: 0.8251\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 79s 255ms/step - loss: 0.3977 - accuracy: 0.8800 - val_loss: 0.3494 - val_accuracy: 0.8859\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 76s 246ms/step - loss: 0.2910 - accuracy: 0.9067 - val_loss: 0.2744 - val_accuracy: 0.9202\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 79s 256ms/step - loss: 0.2547 - accuracy: 0.9148 - val_loss: 0.2772 - val_accuracy: 0.8859\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 76s 248ms/step - loss: 0.2138 - accuracy: 0.9319 - val_loss: 0.2850 - val_accuracy: 0.8669\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 79s 255ms/step - loss: 0.1694 - accuracy: 0.9489 - val_loss: 0.2725 - val_accuracy: 0.8783\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 76s 248ms/step - loss: 0.1668 - accuracy: 0.9424 - val_loss: 0.2380 - val_accuracy: 0.8973\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 77s 248ms/step - loss: 0.1366 - accuracy: 0.9570 - val_loss: 0.2243 - val_accuracy: 0.9163\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 73s 238ms/step - loss: 0.1326 - accuracy: 0.9578 - val_loss: 0.2618 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 78s 251ms/step - loss: 0.1310 - accuracy: 0.9562 - val_loss: 0.2101 - val_accuracy: 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved.\n"
     ]
    }
   ],
   "source": [
    "# train top layers (freeze others)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "model.save(\"fine_tuned_blurry_model2.h5\")\n",
    "print(\"Fine-tuned model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8413b5-6073-4a53-b158-8bc3c8ca60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to fine-tuned model\n",
    "model = load_model(\"fine_tuned_blurry_model.h5\")\n",
    "\n",
    "# Folder with all test images (no class subfolders needed)\n",
    "test_folder = \"vehicle_dataset/test\"\n",
    "img_size = (160, 160)  # same as model input\n",
    "\n",
    "test_files = [f for f in os.listdir(test_folder) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "test_images = []\n",
    "file_names = []\n",
    "\n",
    "for f in test_files:\n",
    "    img_path = os.path.join(test_folder, f)\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0  # rescale like training\n",
    "    test_images.append(img_array)\n",
    "    file_names.append(f)\n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540e5778-72e2-4404-8d88-1beee40c6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from skimage import restoration\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_single_image(model, img_path, class_names):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    preds = model.predict(img, verbose=0)\n",
    "    idx = np.argmax(preds[0])\n",
    "    confidence = preds[0][idx]\n",
    "\n",
    "    return class_names[idx], confidence\n",
    "\n",
    "def run_predictions_finetuned(model, data_dir, class_names):\n",
    "    print(\"\\nRunning predictions on fine-tuned model...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for true_class in class_names:\n",
    "        class_path = os.path.join(data_dir, true_class)\n",
    "\n",
    "        if not os.path.exists(class_path):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(class_path)\n",
    "        if not images:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n  {true_class}/ ({len(images)} images)\")\n",
    "        class_correct = 0\n",
    "\n",
    "        for i, img_file in enumerate(images):\n",
    "            if i % 20 == 0 and i > 0:\n",
    "                print(f\"    {i}/{len(images)}...\")\n",
    "\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "\n",
    "            pred_class, conf = predict_single_image(model, img_path, class_names)\n",
    "            if pred_class is None:  \n",
    "                continue\n",
    "\n",
    "            is_correct = (pred_class == true_class)\n",
    "            if is_correct:\n",
    "                class_correct += 1\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "            results.append({\n",
    "                \"true_class\": true_class,\n",
    "                \"filename\": img_file,\n",
    "                \"predicted_class\": pred_class,\n",
    "                \"confidence\": conf,\n",
    "                \"correct\": is_correct\n",
    "            })\n",
    "\n",
    "        print(f\"    ✓ {class_correct}/{len(images)} \"\n",
    "              f\"= {class_correct/len(images)*100:.1f}%\")\n",
    "\n",
    "    overall = (correct / total) * 100 if total > 0 else 0\n",
    "    print(f\"\\nOverall accuracy: {correct}/{total} = {overall:.2f}%\")\n",
    "\n",
    "    return pd.DataFrame(results), overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7135f2ab-68d6-4f07-abaf-a143f2c3402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions on fine-tuned model...\n",
      "============================================================\n",
      "\n",
      "  bicycle/ (32 images)\n",
      "    20/32...\n",
      "    ✓ 32/32 = 100.0%\n",
      "\n",
      "  boat/ (41 images)\n",
      "    20/41...\n",
      "    40/41...\n",
      "    ✓ 40/41 = 97.6%\n",
      "\n",
      "  bus/ (44 images)\n",
      "    20/44...\n",
      "    40/44...\n",
      "    ✓ 42/44 = 95.5%\n",
      "\n",
      "  car/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 45/45 = 100.0%\n",
      "\n",
      "  helicopter/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 44/45 = 97.8%\n",
      "\n",
      "  motorcycle/ (17 images)\n",
      "    ✓ 15/17 = 88.2%\n",
      "\n",
      "  truck/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 42/45 = 93.3%\n",
      "\n",
      "Overall accuracy: 260/269 = 96.65%\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"fine_tuned_blurry_model2.h5\")\n",
    "df, acc = run_predictions_finetuned(\n",
    "    model,\n",
    "    data_dir=\"vehicle_dataset2/test\",\n",
    "    class_names=YOUR_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80133184-8be0-43d0-aa74-4a7017c8858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions on fine-tuned model...\n",
      "============================================================\n",
      "\n",
      "  bicycle/ (31 images)\n",
      "    20/31...\n",
      "    ✓ 31/31 = 100.0%\n",
      "\n",
      "  boat/ (40 images)\n",
      "    20/40...\n",
      "    ✓ 37/40 = 92.5%\n",
      "\n",
      "  bus/ (42 images)\n",
      "    20/42...\n",
      "    40/42...\n",
      "    ✓ 41/42 = 97.6%\n",
      "\n",
      "  car/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 45/45 = 100.0%\n",
      "\n",
      "  helicopter/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 41/45 = 91.1%\n",
      "\n",
      "  motorcycle/ (15 images)\n",
      "    ✓ 14/15 = 93.3%\n",
      "\n",
      "  truck/ (45 images)\n",
      "    20/45...\n",
      "    40/45...\n",
      "    ✓ 38/45 = 84.4%\n",
      "\n",
      "Overall accuracy: 247/263 = 93.92%\n"
     ]
    }
   ],
   "source": [
    "df2, acc2 = run_predictions_finetuned(\n",
    "    model,\n",
    "    data_dir=\"vehicle_dataset2/val\",\n",
    "    class_names=YOUR_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ba5df-7247-49c5-8d40-a15fc6f8717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
